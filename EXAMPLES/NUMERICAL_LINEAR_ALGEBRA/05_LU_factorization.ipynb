{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. LU Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `fbpca` and our own `randomized_range_finder` methods used LU factorization, which factors a matrix into the product of a lower triangular matrix and an upper triangular matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is based on lectures 20-22 in Trefethen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are unfamiliar with Gaussian elimination or need a refresher, watch [this Khan Academy video](https://www.khanacademy.org/math/precalculus/precalc-matrices/row-echelon-and-gaussian-elimination/v/matrices-reduced-row-echelon-form-2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Gaussian Elimination by hand to review:\n",
    "\n",
    "A =\n",
    " \\begin{pmatrix}\n",
    "  1 & -2 & -2 & -3 \\\\\n",
    "  3 & -9 & 0 & -9 \\\\\n",
    "  -1 & 2 & 4 & 7  \\\\\n",
    "  -3 & -6 & 26 & 2\n",
    " \\end{pmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ LU = \\begin{bmatrix} 1 & 0 & 0 & 0\\\\ 3 & 1 & 0 & 0 \\\\ -1 & 0 & 1 & 0 \\\\ -3 & 4 & -2 & 1\\end{bmatrix} \\cdot \\begin{bmatrix} 1 & -2 & -2 & -3 \\\\ 0 & -3 & 6 & 0 \\\\ 0 & 0 & 2 & 4 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above example is from Lectures 20, 21 of Trefethen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Elimination** transform a linear system into an upper triangular one by applying linear transformations on the left.  It is *triangular triangularization*.\n",
    "\n",
    "$ L_{m-1} \\dots L_2 L_1 A = U $\n",
    "\n",
    "L is *unit lower-triangular*: all diagonal entries are 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LU(A):\n",
    "    U = np.copy(A)\n",
    "    m, n = A.shape\n",
    "    L = np.eye(n)\n",
    "    for k in range(n-1):\n",
    "        for j in range(k+1,n):\n",
    "            L[j,k] = U[j,k]/U[k,k]\n",
    "            U[j,k:n] -= L[j,k] * U[k,k:n]\n",
    "    return L, U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2,1,1,0],[4,3,3,1],[8,7,9,5],[6,7,9,8]]).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, U = LU(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A, L @ U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LU factorization is useful!\n",
    "\n",
    "Solving Ax = b becomes LUx = b:\n",
    "1. find A = LU\n",
    "2. solve Ly = b\n",
    "3. solve Ux = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Work**\n",
    "\n",
    "Work for Gaussian Elimination: $2\\cdot\\frac{1}{3} n^3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory**\n",
    "\n",
    "Above, we created two new matrices, $L$ and $U$.  However, we can store the values of $L$ and $U$ in our matrix A (overwriting the original matrix).  Since the diagonal of $L$ is all $1$s, it doesn't need to be stored.  Doing factorizations or computations **in-place** is a common technique in numerical linear algebra to save memory.  Note: you wouldn't want to do this if you needed to use your original matrix $A$ again in the future.  One of the homework questions is to rewrite the LU method to operate in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the matrix $$ A = \\begin{bmatrix} 10^{-20} & 1 \\\\ 1 & 1 \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1e-20, 1], [1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By hand, use Gaussian Elimination to calculate what L and U are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Exercise:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Exercise:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "L2, U2 = LU(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.e+00, 0.e+00],\n",
       "        [1.e+20, 1.e+00]]),\n",
       " array([[ 1.e-20,  1.e+00],\n",
       "        [ 0.e+00, -1.e+20]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2, U2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'L1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6517d8dc5592>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'L1' is not defined"
     ]
    }
   ],
   "source": [
    "np.allclose(L1, L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.allclose(U1, U2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.allclose(A, L2 @ U2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the motivation for $LU$ factorization **with pivoting**.\n",
    "\n",
    "This also illustrates that LU factorization is *stable*, but not *backward stable*. (spoiler alert: even with partial pivoting, LU is \"explosively unstable\" for certain matrices, yet stable in practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An algorithm $\\hat{f}$ for a problem $f$ is **stable** if for each $x$,\n",
    "$$ \\frac{\\lVert \\hat{f}(x) - f(y) \\rVert}{ \\lVert f(y) \\rVert } = \\mathcal{O}(\\varepsilon_{machine}) $$\n",
    "\n",
    "for some $y$ with\n",
    "$$ \\frac{\\lVert y - x \\rVert }{\\lVert x \\rVert} = \\mathcal{O}(\\varepsilon_{machine}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**A stable algorithm gives nearly the right answer to nearly the right question** (Trefethen, pg 104)\n",
    "\n",
    "To translate that:\n",
    "- right question: $x$\n",
    "- nearly the right question: $y$\n",
    "- right answer: $f$\n",
    "- right answer to nearly the right question: $f(y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Backwards Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Backwards stability is both **stronger** and **simpler** than stability. \n",
    "\n",
    "An algorithm $\\hat{f}$ for a problem $f$ is **backwards stable** if for each $x$,\n",
    "$$ \\hat{f}(x) = f(y) $$\n",
    "\n",
    "for some $y$ with\n",
    "$$ \\frac{\\lVert y - x \\rVert }{\\lVert x \\rVert} = \\mathcal{O}(\\varepsilon_{machine}) $$\n",
    "\n",
    "**A backwards stable algorithm gives exactly the right answer to nearly the right question** (Trefethen, pg 104)\n",
    "\n",
    "Translation:\n",
    "\n",
    "- right question: $x$\n",
    "- nearly the right question: $y$\n",
    "- right answer: $f$\n",
    "- right answer to nearly the right question: $f(y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### LU factorization with Partial Pivoting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's now look at the matrix $$ \\hat{A} = \\begin{bmatrix} 1 & 1 \\\\ 10^{-20} & 1 \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[1,1], [1e-20, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "By hand, use Gaussian Elimination to calculate what L and U are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$ \\hat{L} = \\begin{bmatrix} 1 & 0 \\\\ 10^{-20} & 1 \\end{bmatrix} $$\n",
    "$$ \\hat{U} = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 - 10^{-20} \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "L, U = LU(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.allclose(A, L @ U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Idea: We can switch the order of the rows around to get more stable answers! This is equivalent to multiplying by a permutation matrix $P$.  For instance,\n",
    "\n",
    "$$\\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix} \\cdot \\begin{bmatrix} 10^{-20} & 1 \\\\ 1 & 1 \\end{bmatrix} =  \\begin{bmatrix} 1 & 1 \\\\ 10^{-20} & 1 \\end{bmatrix} $$\n",
    "\n",
    "$$ PA = \\hat{A} $$\n",
    "\n",
    "Apply Gaussian elimination to $PA$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "At each step, choose the largest value in column k, and move that row to be row k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def swap(a,b):\n",
    "    temp = np.copy(a)\n",
    "    a[:] = b\n",
    "    b[:] = temp\n",
    "\n",
    "a=np.array([1,2,3])\n",
    "b=np.array([3,2,1])\n",
    "swap(a,b)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Exercise: re-write the LU factorization above to use pivoting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[2,1,1,0],[4,3,3,1],[8,7,9,5],[6,7,9,8]]).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "L, U, P = LU_pivot(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Can compare below to answers in Trefethen, page 159:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Partial pivoting** permutes the rows. It is such a universal practice, that this is usually what is meant by *LU factorization*.\n",
    "\n",
    "**Complete pivoting** permutes the rows and columns.  Complete pivoting is significantly time-consuming and rarely used in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Consider the system of equations:\n",
    "\n",
    "$$ \\begin{bmatrix} 1 & 0 & 0  & 0 & 0 & 1 \\\\ -1 & 1 & 0  & 0 & 0 & 1 \\\\ -1 & -1 & 1  & 0 & 0 & 1 \\\\ -1 & -1 & -1  & 1 & 0 & 1  \\\\  -1 & -1 & -1  & -1 & 1 & 1 \\\\ -1 & -1 & -1  & -1 & -1 & 1 \\end{bmatrix} \\mathbf{x} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1  \\\\ 1 \\\\ 2 \\\\ 1 \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_matrix(n):\n",
    "    A = np.eye(n)\n",
    "    for i in range(n):\n",
    "        A[i,-1] = 1\n",
    "        for j in range(i):\n",
    "            A[i,j] = -1\n",
    "    return A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_vector(n):\n",
    "    b = np.ones(n)\n",
    "    b[-2] = 2\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "make_vector(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Exercise: Let's use Gaussian Elimination on the $5 \\times 5$ system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Scipy has this funtionality as well.  Let's look at the solution for the last 5 equations with $n=10,\\,20,\\,30,\\,40,\\,50,\\,60$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "?scipy.linalg.solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for n, ls in zip(range(10, 70, 10), ['--', ':', '-', '-.', '--', ':']):\n",
    "    soln = scipy.linalg.lu_solve(scipy.linalg.lu_factor(make_matrix(n)), make_vector(n))\n",
    "    plt.plot(soln[-5:], ls)\n",
    "    print(soln[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is going on when $n=60$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Theorem**: Let the factorization $PA = LU$ of a matrix A be computed by Gaussian Elimination with partial pivoting.  The *computed* (by a computer with Floating Point Arithmetic) matrices $\\hat{P}$, $\\hat{L}$, and $\\hat{U}$ satisfy\n",
    "\n",
    "$$\\hat{L}\\hat{U} = \\hat{P} A + \\delta A, \\quad \\frac{\\delta A}{A} = \\mathcal{O}(\\rho \\varepsilon_{machine}) $$\n",
    "\n",
    "where $\\rho$ is the *growth factor*, \n",
    "\n",
    "$$\\rho = \\frac{max_{i,j} \\lvert u_{ij} \\rvert }{max_{i,j} \\lvert a_{ij} \\rvert } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For our matrix above, $\\rho = 2^{m-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Unstable in theory, stable in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Stability of most algorithms (such as QR) is straightforward.  Not the case for Gaussian Elimination with partial pivoting.  Instability in Gaussian elimination (with or without pivoting) arises only if L and/or U is large relative to the size of A.\n",
    "\n",
    "Trefethen: \"Despite examples like (22.4), Gaussian elimination with partial pivoting is utterly stable in practice... In fifty years of computing, no matrix problems that excite an explosive instability are known to have arisen under natural circumstances.\" [although can easily be constructed as contrived examples]\n",
    "\n",
    "Although some matrices cause instability, but extraordinarily small proportion of all matrices so \"never\" arise in practice for statistical reasons.  \"If you pick a billion matrices at random, you will almost certainly not find one for which Gaussian elimination is unstable.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Further Reading\n",
    "- Gaussian Elimination/LU factorization-- Trefethn Lecture 20\n",
    "- Pivoting -- Trefethn Lecture 21\n",
    "- Stability of Gaussian Elimination -- Trefethn Lecture 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### What is going on with Randomized Projections?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We are taking a linear combination (with random weights) of the columns in the matrix below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(M, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It's like a random weighted average.  If you take several of these, you end up with columns that are not highly correlated to each other (roughly orthogonal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Johnson-Lindenstrauss Lemma**: ([from wikipedia](https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma)) a small set of points in a high-dimensional space can be embedded into a space of much lower dimension in such a way that distances between the points are nearly preserved.\n",
    "\n",
    "It is desirable to be able to reduce dimensionality of data in a way that preserves relevant structure. The Johnson–Lindenstrauss lemma is a classic result of this type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History of Gaussian Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Fun fact: Gauss did not invent Gaussian elimination, but may have discovered Cholesky factorization before Cholesky <a href=\"https://t.co/lWIpRrL7ue\">https://t.co/lWIpRrL7ue</a> <a href=\"https://t.co/CGPJqIWR7H\">pic.twitter.com/CGPJqIWR7H</a></p>&mdash; Rachel Thomas (@math_rachel) <a href=\"https://twitter.com/math_rachel/status/872229937771495424?ref_src=twsrc%5Etfw\">June 6, 2017</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "\n",
    "According to Wikipedia, [**Stigler's Law of Eponymy**](https://en.m.wikipedia.org/wiki/Stigler%27s_law_of_eponymy): \"no scientific discovery is named after its original discoverer. Examples include *Hubble's law* which was derived by Georges Lemaître two years before Edwin Hubble, the *Pythagorean theorem* which was known to Babylonian mathematicians before Pythagoras, and *Halley's comet* which was observed by astronomers since at least 240 BC. Stigler himself named the sociologist Robert K. Merton as the discoverer of *Stigler's law* to show that it follows its own decree, though the phenomenon had previously been noted by others\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Fascinating history of Gaussian Elimination](http://meyer.math.ncsu.edu/Meyer/PS_Files/GaussianEliminationHistory.pdf).  Some highlights:\n",
    "\n",
    "- First written record of Gaussian elimination from ~200 BC in the Chinese book *Nine Chapters on Arithmetic*\n",
    "- The ancient Chinese used colored bamboo rods placed in columns on a \"counting board\"\n",
    "- Japanese mathematicican Seki Kowa (1643-1708) carried forward the Chinese elimintion methods and invented the determinant before 1683.  Around the same time, Leibniz made similar discoveries independently, but neither Kowa nor Leibniz go credit for their discoveries.\n",
    "- Gauss referred to the elimination method as being \"commonly known\" and never claimed to have invented it, although he may have invented the Cholesky decomposition\n",
    "\n",
    "[More history here](http://www.sciencedirect.com/science/article/pii/S0315086010000376)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Speeding Up Gaussian Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Parallelized LU Decomposition](https://courses.engr.illinois.edu/cs554/fa2013/notes/06_lu_8up.pdf) LU decomposition can be fully parallelized\n",
    "\n",
    "[Randomized LU Decomposition](http://www.sciencedirect.com/science/article/pii/S1063520316300069) (2016 article): The randomized LU is fully implemented to run on a standard GPU card without any GPU–CPU data transfer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy.linalg solve vs lu_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 60\n",
    "A = make_matrix(n)\n",
    "b = make_vector(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem has a large *growth factor* $= 2^{59}$.  We get the wrong answer using scipy.linalg.lu_solve, but the right answer with scipy.linalg.solve.  What is scipy.linalg.solve doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scipy.linalg.lu_solve(scipy.linalg.lu_factor(A), b)[-5:])\n",
    "print(scipy.linalg.solve(A, b)[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "soln = scipy.linalg.lu_solve(scipy.linalg.lu_factor(A), b)\n",
    "soln[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "soln = scipy.linalg.solve(A, b)\n",
    "soln[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the [source code for scipy](https://github.com/scipy/scipy/blob/v0.19.0/scipy/linalg/basic.py#L25-L224), we see that it is calling the LAPACK routine `gesvx`.  Here is the [Fortran source code for sgesvx](http://www.netlib.org/lapack/explore-html/d0/db8/group__real_g_esolve_ga982d53a8a62d66af9bcaa50642c95ea4.html#ga982d53a8a62d66af9bcaa50642c95ea4) (`s` refers to single, there is also `dgesvx` for doubles and `cgesvx` for complex numbers).  In the comments, we see that it is computing a *reciprocal pivot growth factor*, so it is taking into account this growth factor and doing something more complex than plain partial pivot LU factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What is the computational complexity (big $\\mathcal{O}$) of matrix multiplication for multiplying two $n \\times n$ matrices $A \\times B = C$?\n",
    "\n",
    "You can learn (or refresh) about big $\\mathcal{O}$ on [Codecademy](https://www.codecademy.com/courses/big-o/0/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this looks like:\n",
    "\n",
    "    for i=1 to n\n",
    "        {read row i of A into fast memory}\n",
    "        for j=1 to n\n",
    "            {read col j of B into fast memory}\n",
    "            for k=1 to n\n",
    "                C[i,j] += A[i,k] x B[k,j]\n",
    "            {write C[i,j] back to slow memory}\n",
    "            \n",
    "**Question**: How many reads and writes are made?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide $A,\\, B,\\, C$ into $N\\times N$ blocks of size $\\frac{n}{N} \\times \\frac{n}{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images/block_matrix.png\" alt=\"Block Matrix\" style=\"width: 80%\"/>\n",
    "  ([Source](http://avishek.net/blog/?p=804))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this looks like:\n",
    "\n",
    "    for i=1 to N\n",
    "        for j=1 to N\n",
    "            for k=1 to N\n",
    "                {read block (i,k) of A}\n",
    "                {read block (k,j) of B}\n",
    "                block (i,j) of C += block of A times block of B\n",
    "            {write block (i,j) of C back to slow memory}\n",
    "            \n",
    "**Question 1**: What is the big-$\\mathcal{O}$ of this?\n",
    "\n",
    "**Question 2**: How many reads and writes are made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
