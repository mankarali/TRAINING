{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA) - Linear\n",
    "\n",
    "[scikit-learn Doc](http://scikit-learn.org/stable/modules/decomposition.html#pca)\n",
    "\n",
    "[scikit-learn Parameters](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA)\n",
    "\n",
    "* Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space.\n",
    "\n",
    "\n",
    "1901 by Karl Pearson\n",
    "\n",
    "* Unsupervised Machine Learning\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Principal_component_analysis)\n",
    "\n",
    "\n",
    "* Statistical procedure that utilise [orthogonal transformation](https://en.wikipedia.org/wiki/Orthogonal_transformation) technology\n",
    "\n",
    "* Convert possible correlated features (predictors) into linearly uncorrelated features (predictors) called **principal components**\n",
    "\n",
    "* \\# of principal components <= number of features (predictors)\n",
    "\n",
    "* First principal component explains the largest possible variance\n",
    "\n",
    "* Each subsequent component has the highest variance subject to the restriction that it must be orthogonal to the preceding components. \n",
    "\n",
    "* A collection of the components are called vectors.\n",
    "\n",
    "* Sensitive to scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "* Used in exploratory data analysis (EDA) \n",
    "\n",
    "* Visualize genetic distance and relatedness between populations. \n",
    "\n",
    "\n",
    "* Method:\n",
    "\n",
    "  * Eigenvalue decomposition of a data covariance (or correlation) matrix\n",
    "\n",
    "  * Singular value decomposition of a data matrix (After mean centering / normalizing ) the data matrix for each attribute.\n",
    "\n",
    "\n",
    "* Output\n",
    "\n",
    "  * Component scores, sometimes called **factor scores** (the transformed variable values)\n",
    "  \n",
    "  * **loadings** (the weight)\n",
    "\n",
    "* Data compression and information preservation \n",
    "\n",
    "* Visualization\n",
    "\n",
    "* Noise filtering\n",
    "\n",
    "* Feature extraction and engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_num = np.random.RandomState(42)\n",
    "X = np.dot(rnd_num.rand(2,2), rnd_num.randn(2, 500)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 0] = - X[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1]);\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Components Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.3)\n",
    "\n",
    "\n",
    "# plot data\n",
    "\n",
    "for k, v in zip(pca.explained_variance_, pca.components_):\n",
    "    vec = v * 3 * np.sqrt(k)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    arrowprops=dict(arrowstyle='<-',\n",
    "                    linewidth=1,\n",
    "                    shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', pca.mean_, pca.mean_ + vec, arrowprops=arrowprops)\n",
    "    ax.text(-0.90, 1.2,'PC1', ha='center', va='center', rotation=-42, size=12)\n",
    "    ax.text(-0.1,-0.6,'PC2', ha='center', va='center', rotation=50, size=12)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Two principal components\n",
    "* Length denotes the significance \n",
    "\n",
    "This transformation from data axes to principal axes is as an affine transformation, which basically means it is composed of a translation, rotation, and uniform scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pca.inverse_transform(X_pca)\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.2);\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], alpha=0.8)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Green is the PCA\n",
    "\n",
    "The light blue is the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
